{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this use case, we will embark on a journey to explore the capabilities of **SAP HANA Cloud vector engine**, **SAP Generative AI Hub** and the **Langchain** Framework. The goal is to equip you with the knowledge and skills to handle unstructured and semi-structured data and build efficient applications.\n",
    "\n",
    "Embed structured and semi-structured data using **Large Language Models** (LLMs) from **SAP Generative AI Hub**. Once the data is embedded, it will be stored in **SAP HANA Cloud** helping to store and query vector embeddings seamlessly. \n",
    "\n",
    "\n",
    "## About the data set\n",
    "\n",
    "The data set is a product catalog of IT accessory products. Here are the main attributes and their descriptions based on the sample data:\n",
    "\n",
    "|Field          |Description            |\n",
    "----------------|-----------------------\n",
    "|**PRODUCT_ID**| A unique identifier for each product.|\n",
    "|**PRODUCT_NAME**| The name of the product, which typically includes the brand and the model.|\n",
    "|**CATEGORY**| The general category of the product, which is \"IT Accessories\" for all entries sampled.|\n",
    "|**DESCRIPTION**| A detailed description of the product, highlighting key features and specifications.|\n",
    "|**UNIT_PRICE**| The price of the product in Euros.|\n",
    "|**UNIT_MEASURE**| The unit of measure for the product, typically \"Each\" indicating pricing per item.|\n",
    "|**SUPPLIER_ID**| A unique identifier for the supplier of the product.|\n",
    "|**SUPPLIER_NAME**| The name of the supplier.|\n",
    "|**LEAD_TIME_DAYS**| The number of days it takes from order to delivery.|\n",
    "|**MIN_ORDER**| The minimum order quantity required.|\n",
    "|**CURRENCY**| The currency of the transaction, which is \"EURO\" for all entries.|\n",
    "|**SUPPLIER_COUNTRY**| The country where the supplier is located, which is \"Germany\" for all sampled entries.|\n",
    "|**SUPPLIER_ADDRESS**| The physical address of the supplier.|\n",
    "|**AVAILABILITY_DAYS**| The number of days the product is available for delivery.|\n",
    "|**SUPPLIER_CITY**| The city where the supplier is located.|\n",
    "|**STOCK_QUANTITY**| The quantity of the product currently in stock.|\n",
    "|**MANUFACTURER**| The company that manufactured the product.|\n",
    "|**CITY_LAT**| Geographical coordinates of the city (latitude)|\n",
    "|**CITY_LONG**| Geographical coordinates of the city (longitude).|\n",
    "|**RATING:**| A rating for the product, which are on a scale from 1 to 5.|\n",
    "\n",
    "</br>\n",
    "\n",
    "> This dataset is structured to support various business operations such as inventory management, order processing, and logistics planning, providing a comprehensive view of product offerings, supplier details, and stock levels. Each entry is highly detailed, suggesting the dataset could be used for analytical purposes, such as optimizing supply chain operations or analyzing sales and marketing strategies.\n",
    "\n",
    "</br>\n",
    "\n",
    "## Retrieval Augmented Generation in generative AI Hub using SAP HANA vector search\n",
    "\n",
    "### Hands-on Retrieval Augmented Generation (RAG) workflow \n",
    "\n",
    "The Retrieval Augmented Generation use case process consists of steps to be completed as seen in the graphic below. \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "> ![title](./images/vector_flow_1.png)\n",
    "\n",
    "<br> \n",
    "\n",
    "\n",
    "\n",
    "1. Documents to be included in vector analysis are fed into the model.\n",
    "\n",
    "2. The contents of the files are split into smaller chunks.\n",
    "\n",
    "3. Embedding functions are used to create embeddings from the file/document chunks.\n",
    "\n",
    "4. The embeddings are then stored as vectors in the SAP HANA Cloud Database.\n",
    "\n",
    "5. When a query or prompt is submitted, the query itself is then embedded into vector form.\n",
    "\n",
    "6. The query vector is compared to the values stored as vectors in SAP HANA Cloud via a similarity/semantic search.\n",
    "\n",
    "7. The most appropriate results are forwarded, along with the original query, to a large language model such as Chat GPT.\n",
    "\n",
    "8. The LLM uses the results of the HANA vector search to augment its own searching capabilities, and the final answer is returned to the user.\n",
    "\n",
    "<!-- - Uses Python code to generate responses for queries using the SDK.\n",
    "\n",
    "- Formats the query and invokes the Generative AI Hub SDK to fetch responses. -->\n",
    "\n",
    "### Setup and configuration\n",
    "\n",
    "- Install required Python modules\n",
    "\n",
    "### Implementing RAG Embeddings\n",
    "\n",
    "- Prepare the documentation for the product catalog in CSV format with each row representing a product.\n",
    "\n",
    "- Connect to the HANA vector storage instance and create a table to store the documentation data.\n",
    "\n",
    "- Populate the table with data and create a REAL_VECTOR column to store embeddings.\n",
    "\n",
    "- Use the Generative AI Hub SDK to define a function to generate embeddings for prompts and perform similarity search using the embeddings.\n",
    "\n",
    "### Enhancing Query Responses\n",
    "\n",
    "- Define a prompt template to provide context to queries.\n",
    "\n",
    "- Modify the function to query the LLM (Large Language Model) based on the prompt template.\n",
    "\n",
    "- Test the model's response using specific queries related to the node library, ensuring it provides contextually relevant responses based on embeddings.\n",
    "\n",
    "> Retrieval augmented generation optimizes the output of large language models by applying more context to prompts.\n",
    "\n",
    "</br>\n",
    "\n",
    "<!-- ### SAP HANA Cloud vector engine\n",
    "\n",
    "Storing vector embeddings within the same database is a strategic move that aligns seamlessly with SAP's commitment to providing a unified platform. This integration eliminates the hurdles posed by data silos, offering a holistic approach to data management. In SAP HANA Cloud, the storage of vector embeddings is seamlessly integrated into the platform's existing structure, allowing users to store them in a designated table. Developers can perform SQL-like queries effortlessly. \n",
    "\n",
    "This means you can execute joins, apply filters, and perform selects by combining vector embeddings with various data types, including transactional, spatial, graph, and JSON data, all within the same SQL environment. The Vector Engine ensures a user-friendly experience, eliminating the need for extensive learning or the adoption of new querying methodologies. Essentially, working with vector embeddings in SAP HANA Cloud is as straightforward as crafting queries in a standard SQL database, offering familiarity and ease of use for developers. -->\n",
    "\n",
    "<!-- ### Hands-on Retrieval Augmented Generation (RAG) workflow  -->\n",
    "\n",
    "\n",
    "\n",
    "<!-- 1. Documents to be included in vector analysis are fed into the model.\n",
    "\n",
    "2. The contents of the files are split into smaller chunks.\n",
    "\n",
    "3. Embedding functions are used to create embeddings from the file/document chunks.\n",
    "\n",
    "4. The embeddings are then stored as vectors in the SAP HANA Cloud Database.\n",
    "\n",
    "5. When a query or prompt is submitted, the query itself is then embedded into vector form.\n",
    "\n",
    "6. The query vector is compared to the values stored as vectors in SAP HANA Cloud via a similarity/semantic search.\n",
    "\n",
    "7. The most appropriate results are forwarded, along with the original query, to a large language model such as Chat GPT.\n",
    "\n",
    "8. The LLM uses the results of the HANA vector search to augment its own searching capabilities, and the final answer is returned to the user. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and configuration\n",
    "\n",
    "The following Python modules are to be installed during this hands-on introduction. \n",
    "\n",
    "#### **hdbcli**\n",
    "\n",
    "The Python Database API Specification v2.0 (PEP 249) defines a set of methods that provides a consistent database interface independent of the actual database being used. The Python extension module for SAP HANA implements PEP 249. Once you install the module, you can access and change the information in SAP HANA databases from Python.\n",
    "\n",
    "\n",
    "#### **generative-ai-hub-sdk**\n",
    "\n",
    "With this SAP python SDK you can leverage the power of generative Models like chatGPT available in SAP's generative AI Hub.\n",
    "\n",
    "#### **Folium**\n",
    "\n",
    "Folium builds on the data wrangling strengths of the Python ecosystem and the mapping strengths of the Leaflet.js library. Manipulate your data in Python, then visualize it in a Leaflet map via folium.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Note:** Jupyter Notebook kernel restart required after package installation.\n",
    "\n",
    "\n",
    "</br>\n",
    "\n",
    "#### Install Python packages\n",
    "\n",
    "Run the following package installations. **pip** is the package installer for Python. You can use pip to install packages from the Python Package Index and other indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hdbcli --break-system-packages\n",
    "!pip install generative-ai-hub-sdk[all] --break-system-packages\n",
    "!pip install folium --break-system-packages\n",
    "!pip install ipywidgets --break-system-packages\n",
    "\n",
    "# kernel restart required!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restart Python kernel\n",
    "\n",
    "The Python kernel needs to be restarted before continuing. \n",
    "\n",
    "> ![title](./images/config_001.png)\n",
    "\n",
    "</br>\n",
    "\n",
    "> **Note** This will take a couple of minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure SAP Generative AI Hub credentials\n",
    "\n",
    "A configuration module has already been executed to enable access to SAP Generative AI foundation models. The detail of this configuration is outside the scope of this workshop.\n",
    "\n",
    "However, the typical configuration is in the following format:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"AICORE_AUTH_URL\": \"https://* * * .authentication.sap.hana.ondemand.com\",\n",
    "  \"AICORE_CLIENT_ID\": \"* * * \",\n",
    "  \"AICORE_CLIENT_SECRET\": \"* * * \",\n",
    "  \"AICORE_RESOURCE_GROUP\": \"* * * \",\n",
    "  \"AICORE_BASE_URL\": \"https://api.ai.* * *.cfapps.sap.hana.ondemand.com/v2\"\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "</br>\n",
    "\n",
    "> Before continuing, please ensure that the Python kernel was restarted!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test SAP Generative AI Hub configuration\n",
    "\n",
    "Run the test below using functionality provided by the generative-ai-hub-sdk by making a call to the text-embedding-ada-002 model via SAP Generative AI foundation-models as initial test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test embeddings\n",
    "\n",
    "from gen_ai_hub.proxy.native.openai import embeddings\n",
    "\n",
    "response = embeddings.create(\n",
    "    input=\"SAP Generative AI Hub is awesome!\",\n",
    "    model_name=\"text-embedding-ada-002\"\n",
    "    \n",
    ")\n",
    "print(response.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the embeddings model\n",
    "Embeddings are vector representations of text data that incorporate the semantic meaning of the text. Define the embeddings object that generates embeddings from text data using the **text-embedding-ada-002** model. This function will be used to generate embeddings from the user's prompts.\n",
    "\n",
    "> An deployment for **text-embedding-ada-002** in SAP Generative AI foundation-models have been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embeddings\n",
    "\n",
    "from gen_ai_hub.proxy.langchain.init_models import init_embedding_model\n",
    "embeddings = init_embedding_model('text-embedding-ada-002')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the LLM model\n",
    "LLM is initialized as an instance of ChatOpenAI with a model named **gpt-4o**. This is used for generating responses or interacting in a chat-like environment.\n",
    "\n",
    "<!-- We can compare how the output produced by RAG is different from the output when we directly pass the prompt to the model. If we directly pass the prompt to the model without RAG, this will be the output. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set llm\n",
    "\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI\n",
    "from gen_ai_hub.proxy.core.proxy_clients import get_proxy_client\n",
    "\n",
    "proxy_client = get_proxy_client('gen-ai-hub')\n",
    "llm = ChatOpenAI(proxy_model_name='gpt-4o', proxy_client=proxy_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask LLM without context\n",
    "\n",
    "After completing the configuration we are ready to ask the first question directly to LLM (gpt-4o) without any business product context to find us products with a rating of 4 and more. The response is arbitrary and does not relate to our product data. \n",
    "\n",
    "</br>\n",
    "\n",
    "> **Note** We can solve this problem by following the next steps in implementing RAG Embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "question = \"Find 5 products with a rating of 4 and more.\"\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI\n",
    "llm.temperature=0.7\n",
    "response = llm.invoke(question)\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing RAG Embeddings\n",
    "\n",
    "Now that all SAP Generative AI Hub configuration steps have been completed, let's continue to process the product catalog data file.\n",
    "\n",
    "### Prepare the documentation for the product catalog in CSV format with each row representing a product\n",
    "\n",
    "This code snippet demonstrates how to load and process text data from a CSV file using the `CSVLoader` from the `langchain.document_loaders.csv_loader` module.\n",
    "\n",
    "This process is useful for handling large text data, making it more manageable or suitable for further processing, analysis, or input into machine learning models, especially when dealing with limitations on input size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process CSV data file\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(\n",
    "    file_path=\"data/new_product.csv\",\n",
    "    csv_args={\n",
    "        \"delimiter\": \";\",\n",
    "        \"quotechar\": '\"',\n",
    "        \"fieldnames\": [\"PRODUCT_ID\",\"PRODUCT_NAME\",\"CATEGORY\",\"DESCRIPTION\",\"UNIT_PRICE\",\"UNIT_MEASURE\",\"SUPPLIER_ID\",\"SUPPLIER_NAME\",\"LEAD_TIME_DAYS\",\"MIN_ORDER\",\"CURRENCY\",\"SUPPLIER_COUNTRY\",\"SUPPLIER_ADDRESS\",\"AVAILABILITY_DAYS\",\"SUPPLIER_CITY\",\"STOCK_QUANTITY\",\"MANUFACTURER\",\"CITY_LAT\",\"CITY_LONG\", \"RATING\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "# Process data\n",
    "\n",
    "text_documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "text_chunks = text_splitter.split_documents(text_documents)\n",
    "print(f\"Number of document chunks: {len(text_chunks)}\")\n",
    "# print(text_chunks)\n",
    "\n",
    "for chunks in text_chunks:\n",
    "    print(chunks.metadata)\n",
    "    print(chunks.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAP HANA Cloud vector engine\n",
    "\n",
    "Storing vector embeddings within the same database is a strategic move that aligns seamlessly with SAP's commitment to providing a unified platform. This integration eliminates the hurdles posed by data silos, offering a holistic approach to data management. In SAP HANA Cloud, the storage of vector embeddings is seamlessly integrated into the platform's existing structure, allowing users to store them in a designated table. Developers can perform SQL-like queries effortlessly. \n",
    "\n",
    "This means you can execute joins, apply filters, and perform selects by combining vector embeddings with various data types, including transactional, spatial, graph, and JSON data, all within the same SQL environment. The Vector Engine ensures a user-friendly experience, eliminating the need for extensive learning or the adoption of new querying methodologies. Essentially, working with vector embeddings in SAP HANA Cloud is as straightforward as crafting queries in a standard SQL database, offering familiarity and ease of use for developers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the HANA vector storage instance and create a table to store the documentation data\n",
    "\n",
    "The provided Python script imports database connection modules and initiates a connection to a SAP HANA Cloud instance using the `dbapi` module. The user is prompted to enter their username and password, which are then used to establish a secure connection to the SAP HANA Cloud database. \n",
    "\n",
    "The `langchain_community.vectorstores.hanavector` library, specifically the `HanaDB` class, from the LangChain community, is designed to interact with vector data stored in SAP HANA Cloud database, and enables developers to utilize SAP HANA Cloud's advanced capabilities for managing and querying vector data, in the context of AI and machine learning applications.\n",
    "\n",
    "</br>\n",
    "\n",
    "> **Note** Use your username and password supplied to logon to the SAP HANA Cloud database. Find the **host_address** in the lesson content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HC Vector Engine\n",
    "\n",
    "from hdbcli import dbapi\n",
    "from langchain_community.vectorstores.hanavector import HanaDB\n",
    "\n",
    "host_address = input(\"Enter HANA Cloud Hostname\")\n",
    "hdb_user = input(\"Enter Username\")\n",
    "hdb_password = input(\"Enter Password :\")\n",
    "\n",
    "connection = dbapi.connect(\n",
    "    host_address,\n",
    "    port=\"443\",\n",
    "    user=hdb_user,\n",
    "    password=hdb_password,\n",
    "    autocommit=True,\n",
    "    sslValidateCertificate=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the table with data and creates a REAL_VECTOR column to store embeddings\n",
    "\n",
    "Create a LangChain VectorStore interface for the HANA database and specify the table (collection) to use for accessing the vector embeddings. Embeddings are vector representations of text data that incorporate the semantic meaning of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a LangChain VectorStore interface for the HANA database and specify the table (collection) to use for accessing the vector embeddings\n",
    "db = HanaDB(\n",
    "    embedding=embeddings, connection=connection, table_name=\"CATALOG_UPDATED_DEV_1_\"+ hdb_user\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete already existing documents from the table\n",
    "db.delete(filter={})\n",
    "\n",
    "# add the loaded document chunks\n",
    "db.add_documents(text_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify product embeddings in SAP HANA Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the table to verify embeddings\n",
    "cursor = connection.cursor()\n",
    "sql = f'SELECT VEC_TEXT, TO_NVARCHAR(VEC_VECTOR) FROM \"{db.table_name}\"'\n",
    "\n",
    "cursor.execute(sql)\n",
    "vectors = cursor.fetchall()\n",
    "\n",
    "for vector in vectors:\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhancing Query Responses\n",
    "\n",
    "### Define a prompt template to provide context to queries\n",
    "\n",
    "Define a prompt template to provide context to our prompts. Thus, when passed to the model, the template will add the necessary context to the prompt so that more accurate results are generated.\n",
    "\n",
    "The answer should contain the requested information about products and their descriptions, formatted according to the specified JSON structure for further use in the SAP HANA JSON Document store.\n",
    "\n",
    "> The created template for the prompt contains two variables - **context** and **question**. These variables will be replaced with the context and question in the upcoming steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "prompt_template = \"\"\"use the following pieces of context to answer the question at the end. If you don't know the answer,\n",
    "    just say you don't know, don't try to make up an answer. Format the results in a list of JSON items with the following keys:\n",
    "\n",
    "        \"PRODUCT_ID\", \n",
    "        \"PRODUCT_NAME\",\n",
    "        \"CATEGORY\",\n",
    "        \"DESCRIPTION\",\n",
    "        \"UNIT_PRICE\",\n",
    "        \"UNIT_MEASURE\",\n",
    "        \"SUPPLIER_ID\",\n",
    "        \"SUPPLIER_NAME\",\n",
    "        \"LEAD_TIME_DAYS\",\n",
    "        \"MIN_ORDER\",\n",
    "        \"CURRENCY\",\n",
    "        \"SUPPLIER_COUNTRY\",\n",
    "        \"SUPPLIER_ADDRESS\",\n",
    "        \"SUPPLIER_CITY\",\n",
    "        \"CITY_LAT\",\n",
    "        \"CITY_LONG\",\n",
    "        \"RATING\"\n",
    "      \n",
    "    \n",
    "    The 'RATING' key value is an integer datatype ranging from 0 stars to 5 stars. Where 0 stars is 'bad' and 5 stars is 'excellent'. Do not include json markdown codeblock syntax in the results for example: ```json ```\n",
    "\n",
    "    {context}\n",
    "\n",
    "    question: {question}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(template = prompt_template, \n",
    "                        input_variables=[\"context\", \"question\"]\n",
    "                       )\n",
    "    \n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Conversational Retrieval Chain with SAP HANA Cloud vector engine\n",
    "\n",
    "\n",
    "This code snippet integrates various components from the `langchain` library to create a retrieval-based question-answering (QA) system. Here's a breakdown of the key parts and their functionality:\n",
    "\n",
    "- **Retriever Initialization:** The `db.as_retriever` function is used to initialize a retriever object with specific search arguments (`'k':20`), which likely defines the number of search results to consider.\n",
    "\n",
    "- **Prompt Template :** The `PromptTemplate` was defined in the previous step that instructs how to use the context to answer a question. It emphasizes not to fabricate answers if the information is unavailable. The template also outlines the structure for the expected JSON output with various product and supplier details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Find products with a rating of 4 and more.\"\n",
    "retriever = db.as_retriever(search_kwargs={'k':20})\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm,\n",
    "                 retriever=retriever, \n",
    "                 chain_type=\"stuff\",\n",
    "                 chain_type_kwargs= chain_type_kwargs)\n",
    "\n",
    "answer = qa.run(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAP HANA Cloud multi-modeling with Spatial and Vector engines\n",
    "\n",
    "#### RAG results to SAP HANA Cloud Document Store (JSON)\n",
    "\n",
    "Create a document collection **GX_RAG_PRODUCTS_DEV** to store the RAG results from the previous step. This script iterates over the list of product dictionaries, converting each one into a JSON string before inserting it into the collection. It then queries the collection to fetch and print all the inserted documents, allowing you to verify the insertion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset of product details\n",
    "import json\n",
    "\n",
    "jdata = json.loads(answer)\n",
    "products = jdata\n",
    "collection_name = \"GX_RAG_PRODUCTS_DEV\"\n",
    "\n",
    "# Create a cursor\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Create a collection (document store)\n",
    "try:\n",
    "    cursor.execute(f\"CREATE COLLECTION {collection_name}\")\n",
    "    print(f\"{collection_name} Created!\")\n",
    "    \n",
    "    # Insert JSON data into the collection\n",
    "    for product in products:\n",
    "        json_str = json.dumps(product)\n",
    "        cursor.execute(f\"INSERT INTO {collection_name} VALUES ('{json_str}')\")\n",
    "\n",
    "except :\n",
    "    print(f\"{collection_name} Recreated!\")\n",
    "    cursor.execute(f\"DROP COLLECTION {collection_name}\")\n",
    "    cursor.execute(f\"CREATE COLLECTION {collection_name}\")\n",
    "\n",
    "    # Insert JSON data into the collection\n",
    "    for product in products:\n",
    "        json_str = json.dumps(product)\n",
    "        cursor.execute(f\"INSERT INTO {collection_name} VALUES ('{json_str}')\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Query SAP HANA Cloud JSON Collection\n",
    "\n",
    "This code snippet is designed to query a collection named **GX_RAG_PRODUCTS_DEV** to retrieve supplier information, including their ID, city, and location represented as a geospatial point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"GX_RAG_PRODUCTS_DEV\"\n",
    "sql = f\"SELECT PRODUCT_ID, PRODUCT_NAME, RATING FROM {collection_name}\"\n",
    "\n",
    "\n",
    "cursor.execute(sql)\n",
    "query_result = cursor.fetchall()\n",
    "\n",
    "for result in query_result:\n",
    "    print(result)\n",
    "\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"GX_RAG_PRODUCTS_DEV\"\n",
    "sql = f\"SELECT SUPPLIER_ID, SUPPLIER_CITY,SUPPLIER_ADDRESS,NEW ST_POINT(TO_DOUBLE(CITY_LONG),TO_DOUBLE(CITY_LAT)) AS SUPPLIER_LOCATION FROM {collection_name}\"\n",
    "\n",
    "\n",
    "cursor.execute(sql)\n",
    "suppliers = cursor.fetchall()\n",
    "\n",
    "for supplier in suppliers:\n",
    "    print(supplier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAP HANA Cloud Spatial engine\n",
    "\n",
    "This code snippet is designed to create a new table called **GX_SUPPLIER_LOCATIONS**, specifically for storing supplier location information. Note that **SUPPLIER_LOCATION** is a geospatial point representing the supplier's location, created using the `ST_POINT()` function. \n",
    "\n",
    "This point is constructed from two columns - **CITY_LONG** and **CITY_LAT** - which are converted to double precision numbers (representing longitude and latitude, respectively).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"GX_SUPPLIER_LOCATIONS_DEV\"\n",
    "sql = f\"\"\"CREATE TABLE {table_name} AS (\n",
    "               SELECT SUPPLIER_ID,\n",
    "               SUPPLIER_CITY,\n",
    "               NEW ST_POINT(\n",
    "               TO_DOUBLE(CITY_LONG),\n",
    "               TO_DOUBLE(CITY_LAT)) AS SUPPLIER_LOCATION,\n",
    "               SUPPLIER_ADDRESS,\n",
    "               PRODUCT_NAME,\n",
    "               RATING\n",
    "\n",
    "               FROM {collection_name})\"\"\"\n",
    "\n",
    "try:\n",
    "    cursor.execute(sql)\n",
    "    print(f\"{table_name} Created!\")\n",
    "\n",
    "except :\n",
    "    print(f\"{table_name} Recreated!\")\n",
    "    cursor.execute(f\"DROP TABLE {table_name}\")\n",
    "    cursor.execute(sql)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Query to new table to fetch the geospatial data. \n",
    "\n",
    "This code snippet is designed to query SAP HANA Cloud using SQL to retrieve information about suppliers, including their IDs, city names, and geographic locations (latitude and longitude). Here's a breakdown of the code's functionality:\n",
    "\n",
    "The latitude and longitude are extracted using the `ST_Y()` and `ST_X()` functions on the **SUPPLIER_LOCATION** column, which is presumably stored as a geospatial data type in the database.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to fetch the geospatial data\n",
    "table_name = \"GX_SUPPLIER_LOCATIONS_DEV\"\n",
    "sql = f\"\"\"SELECT SUPPLIER_ID,\n",
    "               SUPPLIER_CITY,\n",
    "               SUPPLIER_LOCATION.ST_Y() as latitudes, \n",
    "               SUPPLIER_LOCATION.ST_X() as longitudes,\n",
    "               SUPPLIER_ADDRESS,\n",
    "               PRODUCT_NAME,\n",
    "               RATING \n",
    "            FROM {table_name}\"\"\"\n",
    "\n",
    "cursor.execute(sql)\n",
    "\n",
    "# Fetch all the results\n",
    "points = cursor.fetchall()\n",
    "\n",
    "\n",
    "for point in points:\n",
    "    print(point)\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize supplier warehouse locations on a map \n",
    "\n",
    "The provided code snippet uses the Folium library in Python to create an interactive map centered around Germany. It initializes a map object centered at the coordinates for Germany (latitude 51.1657, longitude 10.4515) with a zoom level of 6. Then, it iterates over a dataset named `data`, which is expected to contain points of interest. Each point in the dataset includes a supplier ID, city name, latitude, and longitude.\n",
    "\n",
    "For each point, the code creates a popup text that includes the city name and supplier ID. It then creates a marker at the point's latitude and longitude, attaches the popup text to this marker, and adds the marker to the map. The result is an interactive map where each marker represents a point of interest, and clicking on a marker displays a popup with additional information about that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "data = points\n",
    "\n",
    "# Create a map centered around the average location\n",
    "average_lat = sum([item[2] for item in data]) / len(data)\n",
    "average_lon = sum([item[3] for item in data]) / len(data)\n",
    "map = folium.Map(location=[average_lat, average_lon], zoom_start=7)\n",
    "\n",
    "# Loop through each item in data to create markers\n",
    "for supplier_id, city, lat, lon, address, product, rating in data:\n",
    "    popup_text = f\"Supplier ID: {supplier_id}<br>\"\n",
    "    popup_text += f\"City: {city}<br>\"\n",
    "    popup_text += f\"Address: {address}<br>\"\n",
    "    popup_text += f\"Product: {product}<br>\"\n",
    "    popup_text += f\"Rating: {rating}\"\n",
    "    \n",
    "    # Add a marker to the map\n",
    "    folium.Marker(\n",
    "        [lat, lon],\n",
    "        popup=folium.Popup(popup_text, max_width=300,min_width=300)\n",
    "    ).add_to(map)\n",
    "\n",
    "# Display the map\n",
    "map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_hub_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
