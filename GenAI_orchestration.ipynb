{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This lesson demonstrates how to use the SDK to interact with the Orchestration Service, enabling the creation of AI-driven workflows by seamlessly integrating various modules, such as templating, large language models (LLMs), data masking and content filtering. By leveraging these modules, you can build complex, automated workflows that enhance the capabilities of your AI solutions. For more details on configuring and using these modules, please refer to the [Orchestration Service Documentation](https://help.sap.com/docs/sap-ai-core/sap-ai-core-service-guide/orchestration?locale=en-US).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️  Prerequisites\n",
    "Ensure that the workbook lesson **Orchestration Consumption - Gen AI SDK** steps are followed carefully before continuing this hands-on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and configuration\n",
    "\n",
    "The following Python modules are to be installed during this hands-on introduction. \n",
    "\n",
    "#### **generative-ai-hub-sdk**\n",
    "\n",
    "With this SAP python SDK you can leverage the power of generative Models like chatGPT available in SAP's generative AI Hub.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Note:** Jupyter Notebook kernel restart required after package installation.\n",
    "\n",
    "\n",
    "</br>\n",
    "\n",
    "#### Install Python packages\n",
    "\n",
    "Run the following package installations. **pip** is the package installer for Python. You can use pip to install packages from the Python Package Index and other indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install generative-ai-hub-sdk --break-system-packages\n",
    "!pip install ipywidgets --break-system-packages\n",
    "!pip install pandas --break-system-packages\n",
    "\n",
    "# kernel restart required!!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify SDK version\n",
    "\n",
    "Run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show generative-ai-hub-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restart Python kernel\n",
    "\n",
    "The Python kernel needs to be restarted before continuing. \n",
    "\n",
    "> ![title](./images/config_001.png)\n",
    "\n",
    "</br>\n",
    "\n",
    "> **Note** This will take a couple of minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test embeddings\n",
    "\n",
    "from gen_ai_hub.proxy.native.openai import embeddings\n",
    "\n",
    "response = embeddings.create(\n",
    "    input=\"SAP Generative AI Hub is awesome!\",\n",
    "    model_name=\"text-embedding-ada-002\"\n",
    "    \n",
    ")\n",
    "print(response.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the Orchestration Service\n",
    "\n",
    "Before using the SDK, you need to set up a deployment of the Orchestration Service. \n",
    "\n",
    "This is have been done on and you will use a predefined service. Use the pre-deployed access unique endpoint **YOUR_API_URL** in the lesson.\n",
    "\n",
    "<br>\n",
    "\n",
    ">**Note:** Find the **YOUR_API_URL** endpoint in the **Orchestration Consumption - Gen AI SDK** lesson **Stap 8**! \n",
    "\n",
    "Copy the endpoint and paste it in below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUR_API_URL = input(\"Enter YOUR_API_URL from the lesson\")\n",
    "print(YOUR_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the Template and Default Input Values\n",
    "\n",
    "The Template class is used to define structured message templates for generating dynamic interactions with language models. In this example, the template is designed for a translation assistant, allowing users to specify a language and text for translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "\n",
    "template = Template(\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a helpful translation assistant.\"),\n",
    "        UserMessage(\n",
    "            \"Translate the following text to {{?to_lang}}: {{?text}}\"\n",
    "        ),\n",
    "    ],\n",
    "    defaults=[\n",
    "        TemplateValue(name=\"to_lang\", value=\"German\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">This template can be used to create translation requests where the language and text to be translated are specified dynamically. The placeholders in the UserMessage will be replaced with the actual values provided at runtime, and the default value for the language is set to German."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the LLM\n",
    "\n",
    "The LLM class is used to configure and initialize a language model for generating text based on specific parameters. In this example, we'll use the GPT-4o model to perform the translation task.\n",
    "\n",
    "ℹ️Note that virtual deployment of the language model is managed automatically by the Orchestration Service, so no additional deployment setup is required on your part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "\n",
    "llm = LLM(name=\"gpt-4o\", version=\"latest\", parameters={\"max_tokens\": 256, \"temperature\": 0.2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">This configuration initializes the language model to use the gpt-4o variant with the latest updates. The model will generate responses up to 256 tokens in length and produce more predictable and focused output due to the low temperature setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create the Orchestration Configuration\n",
    "\n",
    "The OrchestrationConfig class is used to create a configuration that integrates various components, such as templates and language models, into a unified orchestration setup. This configuration specifies how these components work together to achieve the desired workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run the Orchestration Request\n",
    "\n",
    "The OrchestrationService class is used to interact with the orchestration service by providing a configuration and invoking its operations. This service handles the execution of workflows defined by the provided configuration and processes inputs accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "orchestration_service = OrchestrationService(api_url=YOUR_API_URL, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the run method with the required template_values. The service will process the input according to the configuration and return the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = orchestration_service.run(template_values=[\n",
    "    TemplateValue(name=\"text\", value=\"The Orchestration Service is working!\")\n",
    "])\n",
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Masking\n",
    "\n",
    "The Data Masking Module anonymizes or pseudonymizes personally identifiable information (PII) before it is processed by the LLM module. When data is anonymized, all identifying information is replaced with placeholders (e.g., MASKED_ENTITY), and the original data cannot be recovered, ensuring that no trace of the original information is retained. In contrast, pseudonymized data is substituted with unique placeholders (e.g., MASKED_ENTITY_ID), allowing the original information to be restored if needed. In both cases, the masking module identifies sensitive data and replaces it with appropriate placeholders before further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.utils import load_text_file\n",
    "from gen_ai_hub.orchestration.models.data_masking import DataMasking\n",
    "from gen_ai_hub.orchestration.models.sap_data_privacy_integration import SAPDataPrivacyIntegration, MaskingMethod, \\\n",
    "    ProfileEntity\n",
    "\n",
    "data_masking = DataMasking(\n",
    "    providers=[\n",
    "        SAPDataPrivacyIntegration(\n",
    "            method=MaskingMethod.ANONYMIZATION,  # or MaskingMethod.PSEUDONYMIZATION\n",
    "            entities=[\n",
    "                ProfileEntity.EMAIL,\n",
    "                ProfileEntity.PHONE,\n",
    "                ProfileEntity.PERSON,\n",
    "                ProfileEntity.ORG,\n",
    "                ProfileEntity.LOCATION\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=Template(\n",
    "        messages=[\n",
    "            SystemMessage(\"You are a helpful AI assistant.\"),\n",
    "            UserMessage(\"Summarize the following CV in 10 sentences: {{?orgCV}}\"),\n",
    "        ]\n",
    "    ),\n",
    "    llm=LLM(\n",
    "        name=\"gpt-4o\",\n",
    "    ),\n",
    "    data_masking=data_masking\n",
    ")\n",
    "\n",
    "cv_as_string = load_text_file(\"data/cv.txt\")\n",
    "\n",
    "result = orchestration_service.run(\n",
    "    config=config,\n",
    "    template_values=[\n",
    "        TemplateValue(name=\"orgCV\", value=cv_as_string)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(result.orchestration_result.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Filtering\n",
    "\n",
    "The Content Filtering Module can be configured to filter both the input to the LLM module (input filter) and the output generated by the LLM (output filter). The module uses predefined classification services to detect inappropriate or unwanted content, allowing flexible configuration through customizable thresholds. These thresholds can be set to control the sensitivity of filtering, ensuring that content meets desired standards before it is processed or returned as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.azure_content_filter import AzureContentFilter, AzureThreshold\n",
    "\n",
    "input_filter= AzureContentFilter(hate=AzureThreshold.ALLOW_SAFE,\n",
    "                                  violence=AzureThreshold.ALLOW_SAFE,\n",
    "                                  self_harm=AzureThreshold.ALLOW_SAFE,\n",
    "                                  sexual=AzureThreshold.ALLOW_SAFE)\n",
    "output_filter = AzureContentFilter(hate=AzureThreshold.ALLOW_SAFE,\n",
    "                                   violence=AzureThreshold.ALLOW_SAFE_LOW,\n",
    "                                   self_harm=AzureThreshold.ALLOW_SAFE_LOW_MEDIUM,\n",
    "                                   sexual=AzureThreshold.ALLOW_ALL)\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=Template(\n",
    "        messages=[\n",
    "            SystemMessage(\"You are a helpful AI assistant.\"),\n",
    "            UserMessage(\"{{?text}}\"),\n",
    "        ]\n",
    "    ),\n",
    "    llm=LLM(\n",
    "        name=\"gpt-4o\",\n",
    "    ),\n",
    "    input_filters=[input_filter],\n",
    "    output_filters=[output_filter]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.exceptions import OrchestrationError\n",
    "\n",
    "try:\n",
    "    result = orchestration_service.run(config=config, template_values=[\n",
    "        TemplateValue(name=\"text\", value=\"I hate you\")\n",
    "    ])\n",
    "except OrchestrationError as error:\n",
    "    print(error.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Examples\n",
    "\n",
    "### Translation Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = OrchestrationService(api_url=YOUR_API_URL)\n",
    "\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "\n",
    "class TranslationService:\n",
    "    def __init__(self, orchestration_service: OrchestrationService):\n",
    "        self.service = orchestration_service\n",
    "        self.config = OrchestrationConfig(\n",
    "            template=Template(\n",
    "                messages=[\n",
    "                    SystemMessage(\"You are a helpful translation assistant.\"),\n",
    "                    UserMessage(\n",
    "                        \"Translate the following text to {{?to_lang}}: {{?text}}\"\n",
    "                    ),\n",
    "                ],\n",
    "                defaults=[\n",
    "                    TemplateValue(name=\"to_lang\", value=\"English\"),\n",
    "                ],\n",
    "            ),\n",
    "            llm=LLM(name=\"gpt-4o\"),\n",
    "        )\n",
    "\n",
    "    def translate(self, text, to_lang):\n",
    "        response = self.service.run(\n",
    "            config=self.config,\n",
    "            template_values=[\n",
    "                TemplateValue(name=\"to_lang\", value=to_lang),\n",
    "                TemplateValue(name=\"text\", value=text),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        return response.orchestration_result.choices[0].message.content\n",
    "\n",
    "translator = TranslationService(orchestration_service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = translator.translate(text=\"Hello, world!\", to_lang=\"Afrikaans\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = translator.translate(text=\"Hello, world!\", to_lang=\"German\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot with Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.message import Message, SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "\n",
    "class ChatBot:\n",
    "    def __init__(self, orchestration_service: OrchestrationService):\n",
    "        self.service = orchestration_service\n",
    "        self.config = OrchestrationConfig(\n",
    "            template=Template(\n",
    "                messages=[\n",
    "                    SystemMessage(\"You are a helpful chatbot assistant.\"),\n",
    "                    UserMessage(\"{{?user_query}}\"),\n",
    "                ],\n",
    "            ),\n",
    "            llm=LLM(name=\"gpt-4o\"),\n",
    "        )\n",
    "        self.history: List[Message] = []\n",
    "\n",
    "    def chat(self, user_input):\n",
    "        response = self.service.run(\n",
    "            config=self.config,\n",
    "            template_values=[\n",
    "                TemplateValue(name=\"user_query\", value=user_input),\n",
    "            ],\n",
    "            history=self.history,\n",
    "        )\n",
    "\n",
    "        message = response.orchestration_result.choices[0].message\n",
    "\n",
    "        self.history = response.module_results.templating\n",
    "        self.history.append(message)\n",
    "\n",
    "        return message.content\n",
    "    \n",
    "bot = ChatBot(orchestration_service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bot.chat(\"Hello, how are you?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bot.chat(\"What's the weather like today?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis with Few Shot Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.message import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    AssistantMessage,\n",
    ")\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "\n",
    "class FewShotLearner:\n",
    "    def __init__(\n",
    "            self,\n",
    "            orchestration_service: OrchestrationService,\n",
    "            system_message: SystemMessage,\n",
    "            examples: List[Tuple[UserMessage, AssistantMessage]],\n",
    "    ):\n",
    "        self.service = orchestration_service\n",
    "        self.config = OrchestrationConfig(\n",
    "            template=self._create_few_shot_template(system_message, examples),\n",
    "            llm=LLM(name=\"gpt-4o\"),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_few_shot_template(\n",
    "            system_message: SystemMessage,\n",
    "            examples: List[Tuple[UserMessage, AssistantMessage]],\n",
    "    ) -> Template:\n",
    "        messages = [system_message]\n",
    "\n",
    "        for example in examples:\n",
    "            messages.append(example[0])\n",
    "            messages.append(example[1])\n",
    "        messages.append(UserMessage(\"{{?user_input}}\"))\n",
    "\n",
    "        return Template(messages=messages)\n",
    "\n",
    "    def predict(self, user_input: str) -> str:\n",
    "        response = self.service.run(\n",
    "            config=self.config,\n",
    "            template_values=[TemplateValue(name=\"user_input\", value=user_input)],\n",
    "        )\n",
    "\n",
    "        return response.orchestration_result.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_examples = [\n",
    "    (UserMessage(\"I love this product!\"), AssistantMessage(\"Positive\")),\n",
    "    (UserMessage(\"This is terrible service.\"), AssistantMessage(\"Negative\")),\n",
    "    (UserMessage(\"The weather is okay today.\"), AssistantMessage(\"Neutral\")),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analyzer = FewShotLearner(\n",
    "    orchestration_service=service,\n",
    "    system_message=SystemMessage(\n",
    "        \"You are a sentiment analysis assistant. Classify the sentiment as Positive, Negative, or Neutral.\"\n",
    "    ),\n",
    "    examples=sentiment_examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentiment_analyzer.predict(\"The movie was a complete waste of time!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentiment_analyzer.predict(\"I'm not sure how I feel about the recent events.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai-orch-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
